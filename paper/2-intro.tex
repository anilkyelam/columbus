\section{Introduction}
\label{sec:intro}

Over the last decade, organizations have increasingly offloaded their
data processing and storage needs to third-party ``cloud'' platforms.
However, the economics of cloud platforms is predicated on high levels
of statistical multiplexing and thus \emph{co-tenancy} --- the
contemporaneous execution of computation from disparate customers on
the same physical hardware -- is the norm.  The risks associated with
this arrangement, both data leakage and interference, are
well-appreciated and have generated both a vast research literature
(starting with Ristenpart et al.~\cite{ristenpartccs2009}) as well as
wide-array of technical isolation countermeasures employed by cloud
platform providers. Most of this work has focused squarely on the risks
of information channels between long-lived, heavy-weight virtual
machines (``instances'' in Amazon parlance) used to virtualize the
traditional notion of dedicated network-connected servers.

However, over the last six years, most of the largest cloud providers have
introduced a \emph{new} ``serverless'' service modality that executes
short-lived, lightweight computations on demand (e.g., Amazon's
Lambda~\cite{awslambda}, Google's Cloud Functions~\cite{gcpfunctions} and
Microsoft's Azure Functions~\cite{azurefunctions}).  These services, by design,
use lighter-weight tenant isolation mechanisms (so-called ``micro-VMs'' or
containers) as well as a fixed system environment to provide low-latency startup
and a reduced memory footprint.  In return, serverless systems can support even
higher levels of statistical multiplexing and thus can offer significant cost
savings to customers whose needs are able to match this model (e.g.,
event-driven computations with embedded state).  However, the security issues
associated with serverless computing are far less well understood than their
heavier weight brethren. While the transient and dynamic nature of serverless
computing pose inherent challenges for attackers, their low-cost and
light-weight isolation potentially present new points of purchase as well.

In our work, we explore these issues through the lens of a singular question:
can a practical covert channel be constructed entirely from existing
``serverless'' cloud services\footnote{We will use the term lambdas to stand for
all such services going forward.}?

Covert channels provide a means of transmitting data that bypasses traditional
monitoring or auditing -- typically by encoding data into some resource access
that is not normally deemed a communications medium but is externally visible.
In virtualized environments, covert channels typically involve some shared
resource (e.g. a cache) for which contention provides a means of signaling.  In
the serverless context, the threat model is that an adversary is able to launch,
or inject code into, lambdas from inside a target organization and wishes to
communicate information to parties outside the organization (i.e., to their own
lambdas) without offering any clear evidence of such (e.g., opening network
connections, etc.)

However, the serverless context presents a number of unique challenges for
implementing covert channels.  First, the physical location of a lambda is 
unknown, as the scheduling and placement of lambdas is
managed by the cloud service provider.  Thus, there is no way to arrange that a
sending lambda and a receiving lambda will execute on the same physical
hardware, \emph{let alone at the same time}.  Second, given this reality, any
serverless covert communications protocol must repeatedly launch lambdas in the
hope that at least two sending and receiving lambdas are co-resident on the same
hardware at the same time.  The extent to which this is practicable, on existing
cloud platforms with reasonable cost, is unknown.  Third, it is not enough to
simply \emph{achieve} co-residency, but any lambdas lucky enough to be
co-resident must be able to quickly determine this fact, and then use the
balance of their limited lifetimes to effect communications.  Finally, since
rendezvous in a serverless system is inherently statistical, any such protocol
must anticipate the potential for interference (i.e., when multiple sending
lambdas happen to be co-resident with one or more receiving lambdas). 

In this paper we address each of these issues in turn and demonstrate
the feasibility of covert communication entirely in the context of the
Amazon's serverless cloud platform.  In particular, we make three key technical
contributions: \\
\begin{itemize}
\item{\bf{Fast co-residence detection.}}  Leveraging the memory-bus contention
  work of Wu et. al~\cite{wuusenix2012}, we develop and implement a
  lambda co-residence detector that is generic, reliable, scalable
  and, most importantly, fast, executing in a matter of seconds for thousands of
  concurrent lambdas.
\item{\bf{Dynamic neighbor discovery.}}  We present a novel protocol
  in which co-resident lambdas communicate their IDs using a hardware-based 
  covert channel in order to identify one another. The protocol
  also allows a sender or receiver lambda to enumerate \emph{all} 
  its co-resident neighbors, a requirement to avoid unwanted communication 
  interference while performing covert communication.
\item{\bf{Covert channel demonstration}}  We use our co-residence detector to
    establish lambda covert channels on AWS. We then perform a study on the
    feasibility of covert communication by 1) estimating the capacity of each
    channel and 2) measuring co-residence density -- that is, for a given number of
    lambdas launched at the same point in time, how many would become co-resident?
    We conduct these measurements across a range of Amazon data centers to establish
    that there is ample lambda co-residence and that covert communication is
    practicable. \\
\end{itemize}

Our implementation is publicly available at 
\textit{\url{https://github.com/anilkyelam/columbus}}.

